# Sample - TensorFlow.js Toxicity

Execute the [toxicity model](https://github.com/tensorflow/tfjs-models/tree/master/toxicity) for [TensorFlow.js](https://www.tensorflow.org/js) on [WarpJS](https://warpjs.com).

The toxicity model detects whether text contains toxic content such as threatening language, insults, obscenities, identity-based hate, or sexually explicit language.

ðŸ‘‰ Try a [live demo](https://warpjs-744h4bixx1x93pg3oxc3hr4cf.storage.googleapis.com/index.html)

## Setup

- Clone the project
- Go to the `warp-samples/tensorflowjs-toxicity` directory
- Run the following commands:

```bash
# install deps
$ npm install

# login to warpjs
$ npx warp login
```

## Run

```bash
# run a dev server
$ npm run dev

# build and deploy to production
$ npm run build
$ npm run deploy
```

## Resources

- [TensorFlow.js](https://www.tensorflow.org/js)
- [Toxicity model](https://github.com/tensorflow/tfjs-models/tree/master/toxicity)
- [Getting started with WarpJS](https://warpjs.dev/docs/getting-started)
- [WarpJS Documentation](https://warpjs.dev)
